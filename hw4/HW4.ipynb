{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision:  HW 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Science: COMS W 4995 005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: October 31, 2024\n",
    "\n",
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this notebook we provide three networks for classifying handwritten digits from the MNIST dataset. The networks are implemented and tested using the Tensorflow framework. The third and final network is a convolutional neural network (CNN aka ConvNet) which achieves 99.18% accuracy on this dataset. \n",
    "\n",
    "    Your task is to re-implement all three networks using Pytorch. You will likely find several Pytorch implementations on the internet. It is ok to study these. However, you must not cut and paste this code into your assignment--you must write this yourself. Furthermore, you need to comment every line of code and succintly explain what it is doing! The MNIST dataset should be loadable from PyTorch/torchvision and part of your assignment is to find this and load it yourself.\n",
    "\n",
    "    Here is what is required:\n",
    "\n",
    "    a) A FULLY commented re-implementation of the networks below using Pytorch.\n",
    "\n",
    "    b) your network trained on the same MNIST data as used here.\n",
    "\n",
    "    c) an evaluation of the accuracy on the MNIST test set.\n",
    "\n",
    "    d) plots of 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "\n",
    "    e) have your training record a log of the validation loss and validation accuracy. \n",
    "\n",
    "    f) have your training continually save the best model so far (as determined by the validation loss).\n",
    "\n",
    "    g) after training, load the saved weights using the best model so far. re-run you accuracy evaluation using these saved weights.\n",
    "\n",
    "    Below we include the Tensorflow examples shown in class.  \n",
    "   <p>&nbsp;</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Convolutional Neural Network in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a python and tensorflow-based solution to the handwritten digits recognition problem. It is based on tensorflow tutorials and Yann LeCun's early work on CNN's. This toturial compares a simple softmax regressor, a multi-layer perceptron (MLP), and a simple convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the MNIST digit dataset directly from tensorflow examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib pandas tensorflow sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import tensorflow and begin an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression Model on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create placeholders for the data. Data will be dumped here when it is batched from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i in range(4):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to do softmax logistic regression. This is a linear layer followed by softmax. Note there are NO hidden layers here. Also note that the digit images (28x28 grayscale images) are reshaped into a 784 element vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the parameters (weights) for our linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use tensorflows initializer to initialize these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our linear layer as a function of the input and the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_regressor = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create our loss function. Note that the cross entropy is $ H_{\\hat{y}}(y) = -\\sum_i \\hat{y}_{i} \\, \\log(y_{i})$ where $\\hat{y}$ is the true probability distribution and is expressed as a one-hot vector, $y$ is the estimated probability distribution, and $i$ indexes elements of these two vectors. Also note that this reduces to $ H_{\\hat{y}}(y) = -\\, \\log(y_{i^*})$ where $i^*$ is the correct label. And if we sum this over all of our samples indexed by $j$, then $H_{\\hat{y}}(y) = -\\sum_j  \\log(y^{(j)}_{i^*})$. This is precisely the same loss function as we used before, but we called the MLE loss. They are one and the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_regressor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell tf to use gradient descent with a step size of 0.5 and to minimize the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train by grabbing mini-batches with 100 samples each and pushing these through the network to update our weights (W and b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define how to compute correct predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_regressor,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from these correct predictions how to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out some test images and the corresponsing predictions made by the network. But first, let's add an output to the computation graph that computes the softmax probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_regressor = tf.nn.softmax(logits=y_regressor, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print (\"Label = \", label)\n",
    "    print (\"Class probabilities = \", y_probs_regressor.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Multi-Layer Perceptron on the MNIST Digits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define both weight and bias variables and how they are to be initialized. Note that the weights are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create placeholders for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the first and only fully connected hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_h = weight_variable([784, 512])\n",
    "b_h = bias_variable([512])\n",
    "h = tf.nn.relu(tf.matmul(x, W_h) + b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_out = weight_variable([512, 10])\n",
    "b_out = bias_variable([10])\n",
    "y_MLP = tf.matmul(h, W_out) + b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use cross entropy loss on a softmax distribution on the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training. Note this softmax MLP network does quite a bit bettter than our softmax regressor. The non-linear layer really helps makes sense of the data! But we can do better still..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_MLP,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Convolutional Neural Network: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make our first CNN. It's quite simple network, but it's surprisingly good at this handwritten digit recognition task. This a variant on Yann LeCun's CNN network that really helped to move deep learning forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define both weight and bias variables and how they are to be initialized. Note that the weights are are distributed according to a standard normal distribution (mean = 0, std = 0.1). This random initialization helps avoid hidden units get stuck together, as units that start with the same value will be updated identically in the non-convolutional layers. In contrast, the bias variables are set to a small positive number--this is help prevent hidden units from starting out and getting stuck in the zero part of the ReLu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define how the convolution is to be computed and the extent and type of pooling. The convolution will use a 5x5 kernel and will pad the image with zeros around the edges and use a stride of 1 pixel so that the resulting image (after convolution) has the same size as the original input image. The network will learn the weights for a stack of 32 separate kernels along with 32 bias variables. Finally, after the ReLu is performed the result will be under go 2x2 max pooling, thus halfing both dimensions of the image. The choices for the stride, padding, and pooling are not parameters that the network needs to estimate. Rather these are termed \"hyperparamters\" that are usually set by the network designer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the weight and bias variables for the first convolutional layer as described above. Note the output has depth 32, so there will be 32 feature images after this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike for our softmax regressor above, here we need keep the images as images and not collapse these into vectors; this allows us to perform the 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define are first layer of our CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And wasting no time, we define are second layer. The second layer will have to process 32 feature images coming out of the first layer. Note that the images input to this layer have $\\frac{1}{4}$ the number of pixels as the original input images due to the 2x2 pooling in the previous layer. Note that convolution layer NOT fully connected as our previous hidden layers have been. A unit in the output layer has a limited \"receptive field.\" Its connections to the input layer are spatially limited by the kernel (or filter) size. Also, because of weight sharing in convolutional layers, the number of parameters for a convolutional is the size of the kernel x the depth of the input layer x depth of the output layer + depth of the output layer. So for the second layer of our ConvNet, we have 5 x 5 x 32 x 64 + 64 = 51,264 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pooling stage of our second convolutional layer, we have 64 7x7 \"feature\" images. In one penultimate fully connected hidden layer, we are going to map these feature imges to a 1024 dimensional feature space. Note we need to flatten these feature images to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is added here, although it is not really needed for such small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a final linear output layer mapping features to scores topped off with a softmax cross entropy loss function, as explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we choose an Adam learning rate and update rule. We then run this for 20,000 iterations and evaluate our accuracy after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%1000 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an output to compuational graph that computes the label probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_probs = tf.nn.softmax(logits=y_conv, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we step through some test examples and see how well the network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    batch = mnist.test.next_batch(1)\n",
    "    image = np.asarray(batch[0]).reshape((28, 28))\n",
    "    label = batch[1]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print (\"Label = \", label)\n",
    "    print (\"Class probabilities = \", y_probs.eval(feed_dict={\n",
    "        x: batch[0], y_: batch[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Softmax Regression Model on the MNIST Digits Data, Softmax Multi-Layer Perceptron on the MNIST Digits Data, CNN LeNet\n",
    "\n",
    "- Instructions copied over using PyTorch/torchvision:\n",
    "1) A FULLY commented re-implementation of the networks below using Pytorch.\n",
    "2) your network trained on the same MNIST data as used here.\n",
    "3) an evaluation of the accuracy on the MNIST test set.\n",
    "4) plots of 10 randomly selected digits from the test set along with the correct label and the assigned label.\n",
    "5) have your training record a log of the validation loss and validation accuracy. \n",
    "6) have your training continually save the best model so far (as determined by the validation loss).\n",
    "7) after training, load the saved weights using the best model so far. re-run you accuracy evaluation using these saved weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 4.0002, Val Loss: 3.2235, Val Accuracy: 77.37%\n",
      "Best model saved with validation loss: 3.2235\n",
      "Epoch [2/5], Train Loss: 1.5493, Val Loss: 0.9533, Val Accuracy: 89.48%\n",
      "Best model saved with validation loss: 0.9533\n",
      "Epoch [3/5], Train Loss: 1.4143, Val Loss: 1.0596, Val Accuracy: 88.50%\n",
      "Epoch [4/5], Train Loss: 1.3656, Val Loss: 1.0105, Val Accuracy: 89.26%\n",
      "Epoch [5/5], Train Loss: 1.3333, Val Loss: 1.3533, Val Accuracy: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rosh\\AppData\\Local\\Temp\\ipykernel_6320\\3970282097.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the 10000 test images: 89.48%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.5\n",
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "\n",
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define Softmax Regression Model\n",
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "model = SoftmaxRegression(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Variables to keep track of the best model\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "# Training and validation logging\n",
    "training_log = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss for this epoch\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss and accuracy for this epoch\n",
    "    avg_val_loss = running_val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Logging the metrics for this epoch\n",
    "    training_log['epoch'].append(epoch + 1)\n",
    "    training_log['train_loss'].append(avg_train_loss)\n",
    "    training_log['val_loss'].append(avg_val_loss)\n",
    "    training_log['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = SoftmaxRegression(input_size, num_classes)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the best model on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot 10 random images with true and predicted labels\n",
    "def plot_random_predictions(model, test_loader):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get a batch of test data\n",
    "    images, labels = next(iter(test_loader))\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Select 10 random indices from the batch\n",
    "    random_indices = random.sample(range(len(images)), 10)\n",
    "    \n",
    "    # Plot the images along with true and predicted labels\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        img = images[idx].squeeze()  # Remove unnecessary dimensions\n",
    "        label = labels[idx].item()\n",
    "        pred_label = predicted[idx].item()\n",
    "        \n",
    "        plt.subplot(2, 5, i + 1)  # Arrange plots in a 2x5 grid\n",
    "        plt.imshow(img, cmap='gray')  # Display image in grayscale\n",
    "        plt.title(f'True: {label} | Pred: {pred_label}')\n",
    "        plt.axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the model and test_loader\n",
    "plot_random_predictions(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/42], Train Loss: 0.4321, Val Loss: 0.2797, Val Accuracy: 91.82%\n",
      "Best model saved with validation loss: 0.2797\n",
      "Epoch [2/42], Train Loss: 0.2406, Val Loss: 0.2142, Val Accuracy: 93.78%\n",
      "Best model saved with validation loss: 0.2142\n",
      "Epoch [3/42], Train Loss: 0.1734, Val Loss: 0.1707, Val Accuracy: 94.83%\n",
      "Best model saved with validation loss: 0.1707\n",
      "Epoch [4/42], Train Loss: 0.1366, Val Loss: 0.1383, Val Accuracy: 95.85%\n",
      "Best model saved with validation loss: 0.1383\n",
      "Epoch [5/42], Train Loss: 0.1144, Val Loss: 0.1234, Val Accuracy: 96.22%\n",
      "Best model saved with validation loss: 0.1234\n",
      "Epoch [6/42], Train Loss: 0.0973, Val Loss: 0.1302, Val Accuracy: 95.99%\n",
      "Epoch [7/42], Train Loss: 0.0845, Val Loss: 0.1072, Val Accuracy: 96.88%\n",
      "Best model saved with validation loss: 0.1072\n",
      "Epoch [8/42], Train Loss: 0.0747, Val Loss: 0.0965, Val Accuracy: 97.07%\n",
      "Best model saved with validation loss: 0.0965\n",
      "Epoch [9/42], Train Loss: 0.0664, Val Loss: 0.1091, Val Accuracy: 96.67%\n",
      "Epoch [10/42], Train Loss: 0.0596, Val Loss: 0.0955, Val Accuracy: 97.17%\n",
      "Best model saved with validation loss: 0.0955\n",
      "Epoch [11/42], Train Loss: 0.0568, Val Loss: 0.0844, Val Accuracy: 97.47%\n",
      "Best model saved with validation loss: 0.0844\n",
      "Epoch [12/42], Train Loss: 0.0493, Val Loss: 0.0833, Val Accuracy: 97.55%\n",
      "Best model saved with validation loss: 0.0833\n",
      "Epoch [13/42], Train Loss: 0.0470, Val Loss: 0.0867, Val Accuracy: 97.29%\n",
      "Epoch [14/42], Train Loss: 0.0430, Val Loss: 0.1048, Val Accuracy: 96.83%\n",
      "Epoch [15/42], Train Loss: 0.0392, Val Loss: 0.0949, Val Accuracy: 97.17%\n",
      "Epoch [16/42], Train Loss: 0.0366, Val Loss: 0.0824, Val Accuracy: 97.78%\n",
      "Best model saved with validation loss: 0.0824\n",
      "Epoch [17/42], Train Loss: 0.0355, Val Loss: 0.0876, Val Accuracy: 97.55%\n",
      "Epoch [18/42], Train Loss: 0.0315, Val Loss: 0.0876, Val Accuracy: 97.60%\n",
      "Epoch [19/42], Train Loss: 0.0274, Val Loss: 0.0838, Val Accuracy: 97.74%\n",
      "Epoch [20/42], Train Loss: 0.0260, Val Loss: 0.0840, Val Accuracy: 97.59%\n",
      "Epoch [21/42], Train Loss: 0.0226, Val Loss: 0.1007, Val Accuracy: 97.27%\n",
      "Epoch [22/42], Train Loss: 0.0269, Val Loss: 0.1051, Val Accuracy: 97.06%\n",
      "Epoch [23/42], Train Loss: 0.0224, Val Loss: 0.0937, Val Accuracy: 97.54%\n",
      "Epoch [24/42], Train Loss: 0.0211, Val Loss: 0.0989, Val Accuracy: 97.49%\n",
      "Epoch [25/42], Train Loss: 0.0183, Val Loss: 0.0894, Val Accuracy: 97.80%\n",
      "Epoch [26/42], Train Loss: 0.0183, Val Loss: 0.0953, Val Accuracy: 97.53%\n",
      "Epoch [27/42], Train Loss: 0.0180, Val Loss: 0.1017, Val Accuracy: 97.68%\n",
      "Epoch [28/42], Train Loss: 0.0194, Val Loss: 0.1172, Val Accuracy: 97.31%\n",
      "Epoch [29/42], Train Loss: 0.0175, Val Loss: 0.1021, Val Accuracy: 97.70%\n",
      "Epoch [30/42], Train Loss: 0.0141, Val Loss: 0.1145, Val Accuracy: 97.28%\n",
      "Epoch [31/42], Train Loss: 0.0133, Val Loss: 0.1090, Val Accuracy: 97.32%\n",
      "Epoch [32/42], Train Loss: 0.0133, Val Loss: 0.1002, Val Accuracy: 97.69%\n",
      "Epoch [33/42], Train Loss: 0.0129, Val Loss: 0.1036, Val Accuracy: 97.50%\n",
      "Epoch [34/42], Train Loss: 0.0163, Val Loss: 0.1105, Val Accuracy: 97.37%\n",
      "Epoch [35/42], Train Loss: 0.0153, Val Loss: 0.1203, Val Accuracy: 97.31%\n",
      "Epoch [36/42], Train Loss: 0.0127, Val Loss: 0.1089, Val Accuracy: 97.51%\n",
      "Epoch [37/42], Train Loss: 0.0105, Val Loss: 0.1189, Val Accuracy: 97.47%\n",
      "Epoch [38/42], Train Loss: 0.0117, Val Loss: 0.1233, Val Accuracy: 97.38%\n",
      "Epoch [39/42], Train Loss: 0.0129, Val Loss: 0.1104, Val Accuracy: 97.62%\n",
      "Epoch [40/42], Train Loss: 0.0076, Val Loss: 0.1170, Val Accuracy: 97.63%\n",
      "Epoch [41/42], Train Loss: 0.0144, Val Loss: 0.1134, Val Accuracy: 97.72%\n",
      "Epoch [42/42], Train Loss: 0.0037, Val Loss: 0.1055, Val Accuracy: 97.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rosh\\AppData\\Local\\Temp\\ipykernel_6320\\569634042.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model evaluation on test set - Loss: 0.0857, Accuracy: 97.43%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # Import neural network modules\n",
    "import torch.optim as optim  # Import optimization algorithms\n",
    "from torchvision import datasets, transforms  # Import dataset and transformations\n",
    "from torch.utils.data import DataLoader, random_split  # For data loading and splitting\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "batch_size = 100  # Number of samples per batch\n",
    "num_iterations = 20000  # Total number of training iterations\n",
    "\n",
    "# Define data transformations: convert images to tensors and normalize pixel values\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize tensors to have mean 0.5 and std 0.5\n",
    "])\n",
    "\n",
    "# Load the full MNIST training dataset\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Split the full training dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_train_dataset))  # Calculate training set size\n",
    "val_size = len(full_train_dataset) - train_size  # Calculate validation set size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])  # Split dataset\n",
    "\n",
    "# Create data loaders for training and validation datasets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)  # Training data loader\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)  # Validation data loader\n",
    "\n",
    "# Load the test dataset (used only for final evaluation)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)  # Test data loader\n",
    "\n",
    "# Calculate the number of epochs needed to reach the total number of iterations\n",
    "iterations_per_epoch = len(train_loader)  # Number of batches per epoch\n",
    "num_epochs = num_iterations // iterations_per_epoch + 1  # Total number of epochs\n",
    "\n",
    "# Define a Multi-Layer Perceptron (MLP) model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define the first fully connected layer (input to hidden)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Maps input features to hidden layer\n",
    "        self.relu = nn.ReLU()  # Activation function introducing non-linearity\n",
    "        # Define the second fully connected layer (hidden to output)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # Maps hidden layer to output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten images from (batch_size, 1, 28, 28) to (batch_size, 784)\n",
    "        x = self.fc1(x)  # Pass data through the first layer\n",
    "        x = self.relu(x)  # Apply ReLU activation function\n",
    "        x = self.fc2(x)  # Pass data through the second layer\n",
    "        return x  # Output raw scores (logits) for each class\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 28 * 28  # Each image has 784 pixels\n",
    "hidden_size = 128  # Increased hidden layer size for better performance\n",
    "num_classes = 10  # Number of classes (digits 0-9)\n",
    "model = MLP(input_size, hidden_size, num_classes)  # Create an instance of the MLP model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer for training\n",
    "\n",
    "# Variables to keep track of the best model based on validation loss\n",
    "best_val_loss = float('inf')  # Initialize best validation loss to infinity\n",
    "best_model_path = 'best_model_mlp.pth'  # File path to save the best model weights\n",
    "\n",
    "# Dictionary to record training and validation metrics\n",
    "training_log = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "# Helper function to evaluate the model on validation or test data\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batch norm, etc.)\n",
    "    running_loss = 0.0  # Sum of losses over the dataset\n",
    "    correct = 0  # Number of correct predictions\n",
    "    total = 0  # Total number of samples\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)  # Forward pass to get outputs\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            running_loss += loss.item() * images.size(0)  # Accumulate weighted loss\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class labels\n",
    "            total += labels.size(0)  # Increment total samples\n",
    "            correct += (predicted == labels).sum().item()  # Increment correct predictions\n",
    "\n",
    "    avg_loss = running_loss / total  # Calculate average loss over all samples\n",
    "    accuracy = 100 * correct / total  # Calculate accuracy percentage\n",
    "    return avg_loss, accuracy  # Return average loss and accuracy\n",
    "\n",
    "# Training loop\n",
    "iterations = 0  # Counter for total iterations\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_train_loss = 0.0  # Sum of training losses\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass: compute predicted outputs\n",
    "        outputs = model(images)  # Get model predictions\n",
    "        loss = criterion(outputs, labels)  # Compute loss between predictions and true labels\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear gradients from previous step\n",
    "        loss.backward()  # Compute gradients of the loss w.r.t model parameters\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        running_train_loss += loss.item() * images.size(0)  # Accumulate weighted training loss\n",
    "        iterations += 1  # Increment iteration count\n",
    "\n",
    "        # Check if the desired number of iterations is reached\n",
    "        if iterations >= num_iterations:\n",
    "            break  # Exit the batch loop\n",
    "    # Calculate average training loss for the epoch\n",
    "    avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    avg_val_loss, val_accuracy = evaluate_model(model, val_loader)\n",
    "\n",
    "    # Record metrics in the training log\n",
    "    training_log['epoch'].append(epoch + 1)\n",
    "    training_log['train_loss'].append(avg_train_loss)\n",
    "    training_log['val_loss'].append(avg_val_loss)\n",
    "    training_log['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "    # Print epoch metrics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model if it has the best validation loss so far\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss  # Update best validation loss\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save model weights\n",
    "        print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    # Break the epoch loop if desired iterations are reached\n",
    "    if iterations >= num_iterations:\n",
    "        break  # Exit the epoch loop\n",
    "\n",
    "# Load the best model weights after training\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Best model evaluation on test set - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_random_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN LeNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
